{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b226d257-b62a-420a-b1e1-60d8dd975937",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import json\n",
    "import imageio\n",
    "import requests\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "from moviepy.editor import VideoFileClip\n",
    "from utils import encode_image\n",
    "from movieseq import MovieSeq\n",
    "\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "import whisperx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e5082e5-b4f8-4c5b-9607-ce9a73deb17f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No language specified, language will be first be detected for each audio file (increases inference time).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.2.0.post0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../../../home/qinghong/.cache/torch/whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.1+cu117. Bad things might happen unless you revert torch to 1.x.\n"
     ]
    }
   ],
   "source": [
    "# Set up OPENAI KEY and Models\n",
    "os.environ['OPENAI_API_KEY'] = \n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Please provide Huggingface tokens to access speaker-identify model\n",
    "HF_TOKEN = \n",
    "\n",
    "# load whisperx model\n",
    "model = whisperx.load_model('large-v3', device='cuda')\n",
    "model_a, metadata = whisperx.load_align_model(language_code='en', device='cuda')\n",
    "diarize_model = whisperx.DiarizationPipeline(model_name='pyannote/speaker-diarization-3.1', use_auth_token=HF_TOKEN, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac5b58e8-30da-4ab1-81e8-bff1bf5602c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vid_url\n",
    "vid_url = 'input_clip.mp4'\n",
    "\n",
    "# proceed the video into # clips\n",
    "cut_clip = 4\n",
    "\n",
    "# Context -- Character / Images\n",
    "char_dir = 'char_bank'\n",
    "char_bank = {\n",
    "    'Mia': f'{char_dir}/character1.jpg',\n",
    "    'Sebastian': f'{char_dir}/character2.jpg'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "987a345d-4ba7-4c39-b8a9-0235479ca1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dialogue(video_path):\n",
    "    audio = whisperx.load_audio(video_path)\n",
    "    result = model.transcribe(audio, batch_size=32)\n",
    "    result_a = whisperx.align(result[\"segments\"], model_a, metadata, audio,\n",
    "                              return_char_alignments=False, device='cuda')\n",
    "    \n",
    "    diarize_segments = diarize_model(audio)\n",
    "    result_id = whisperx.assign_word_speakers(diarize_segments, result_a)\n",
    "    return result_id\n",
    "\n",
    "def prepare_context(vid_url, cut_clip):\n",
    "    # Context -- Dialogue / Subtitles\n",
    "    vid_asr_id = prepare_dialogue(vid_url)\n",
    "\n",
    "    # Video sampling and prepare keyframes & dialogues\n",
    "    video = VideoFileClip(vid_url)\n",
    "    duration = video.duration\n",
    "\n",
    "    prev_speaker = None\n",
    "    current_segment = []\n",
    "    all_segments = []\n",
    "    start_timestamps = []\n",
    "\n",
    "    for x in vid_asr_id['segments']:\n",
    "        if 'speaker' in x:\n",
    "            if prev_speaker is None:\n",
    "                prev_speaker = x['speaker']\n",
    "                start_timestamps.append(x['start'])\n",
    "            \n",
    "            if x['speaker'] == prev_speaker:\n",
    "                current_segment.append(f\"{x['text']}\")\n",
    "            else:\n",
    "                all_segments.append(f\"{prev_speaker}: {' '.join(current_segment)}\")\n",
    "                current_segment = [f\"{x['text']}\"]\n",
    "                prev_speaker = x['speaker']\n",
    "                start_timestamps.append(x['start'])\n",
    "\n",
    "    if current_segment:\n",
    "        all_segments.append(f\"{prev_speaker}: {' '.join(current_segment)}\")\n",
    "\n",
    "    asr_list = [all_segments[i:i + cut_clip] for i in range(0, len(all_segments), cut_clip)]\n",
    "    timestamps = [start_timestamps[i] for i in range(0, len(start_timestamps), cut_clip)]\n",
    "\n",
    "    time_list = []\n",
    "    diag_list = []\n",
    "    for i, clips in enumerate(asr_list):\n",
    "        time_list.append(timestamps[i])\n",
    "        diag_list.append(f\" \".join(clips))\n",
    "\n",
    "    output_dir = 'frames'\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    frame_list = []\n",
    "    for timestamp in time_list:\n",
    "        frame = video.get_frame(timestamp)\n",
    "        frame_path = os.path.join(output_dir, f\"{timestamp:.1f}.jpg\")\n",
    "        imageio.imwrite(frame_path, frame)\n",
    "        frame_list.append(frame_path)\n",
    "\n",
    "    return diag_list, frame_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af4242b2-8c17-4d09-a041-e706d0af7387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected language: en (0.98) in first 30s of audio...\n"
     ]
    }
   ],
   "source": [
    "movieseq = MovieSeq()\n",
    "diag_list, frame_list = prepare_context(vid_url, cut_clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "883ee5b4-7472-4d3c-984b-2b041b84ab45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Based on the provided dialogues and the photos, the video features two characters: Mia and Sebastian. Mia is the character in the first photo you provided, and Sebastian is the character in the second photo. The dialogue involves a conversation between these two characters, with Mia being referred to as SPEAKER_00 and Sebastian as SPEAKER_01.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Who is in this video?\"\n",
    "movieseq.get_response(char_bank, frame_list, diag_list, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c5749ae8-8081-40e6-b31f-89e75051c2a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sebastian is wearing a white shirt and a dark-colored jacket, which appears to be either black or navy blue.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What colors did Sebastian wear?\"\n",
    "movieseq.get_response(char_bank, frame_list, diag_list, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0bd56684-21dd-4753-82f9-e43d2c2867ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Based on the dialogue provided, it seems that Sebastian\\'s feelings towards Mia evolve over the course of their conversation. Initially, there is a sense of tension and perhaps irritation, as indicated by his admission of being \"an asshole\" and his defensive stance about being a \"serious musician.\" However, as the conversation progresses, there is a shift in tone. Sebastian becomes more curious and somewhat playful, especially when he asks if he has seen Mia in anything and when he makes a light-hearted comment about her being a barista.\\n\\nBy the end of the conversation, Sebastian\\'s tone appears to be more respectful and intrigued. His final line, \"Guess I\\'ll see you in the movies,\" suggests a level of acknowledgment and perhaps a budding interest in Mia. Overall, it seems that Sebastian\\'s feelings transition from initial defensiveness to curiosity and a hint of admiration.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Can you infer what feelings Sebastian has for Mia?\"\n",
    "movieseq.get_response(char_bank, frame_list, diag_list, query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
